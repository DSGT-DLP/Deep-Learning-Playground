openapi: "3.0.0"
info:
  title: DLP API
  description: API endpoints for the Deep Learning Playground Project
  version: "1.0.0"
paths:
  /api/img-run:
    post:
      description: Endpoint to train image models
      requestBody:
        content:
          application/json:
            schema:
              type: object
              required:
                - train_transform
                - test_transform
                - user_arch
                - using_default_dataset
                - custom_model_name
                - execution_id
                - optimizer_name
                - criterion
                - epochs
                - shuffle
                - batch_size
                - uid
              properties:
                train_transform:
                  type: array
                  description: transformations on images of the train dataset
                test_transform:
                  type: array
                  description: transformations on images of the test dataset
                user_arch:
                  type: array
                  description: Architecture of the model
                uid:
                  type: string
                  description: user id
                custom_model_name:
                  type: string
                  description: name of the model
                execution_id:
                  type: string
                  description: id of the process in the execution table
                optimizer_name:
                  type: string
                  description: optimizer selected (SGD, ADAM)
                criterion:
                  type: string
                  description: criterion selected (BCELOSS, CELOSS)
                using_default_dataset:
                  type: string
                  description: default dataset selected
                epochs:
                  type: int
                  description: number of epochs
                shuffle:
                  type: bool
                  description: determines whether to shuffle the datasets
                batch_size:
                  type: int
                  description: size of the batch
              example:
                train_transforms: [val1, val2, val3]
                test_transforms: [val1, val2, val3]
                user_arch: [val1, val2, val3]
                uid: "user"
                custom_model_name: "model"
                execution_id: "abcde"
                target: "target"
                optimizer_name: "SGD"
                criterion: "CELOSS"
                using_default_dataset: "IRIS"
                epochs: 10
                shuffle: True
                test_size: 0.2
                batch_size: 10
        required: true
      responses:
        "200":
          description: Trained model successfully
          content:
            application/json:
              schema:
                type: object
                properties:
                  message:
                    type: string
                    example: "Dataset trained and results outputted successfully"
                  dl_results:
                    type: object
                    example: { "col1": [val1, val2], "col2": [val3, val4] }
                  auxiliary_outputs:
                    type: object
                    example: { "col1": [val1, val2], "col2": [val3, val4] }
        "400":
          description: Training didn't go through successfully. This is usually something wrong with your code
        "401":
          description: User is not authenticated
          content:
            application/json:
              schema:
                type: object
                properties:
                  error:
                    type: string
                    example: "User is not authenticated"
